{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24058263it [00:34, 690078.54it/s]\n"
     ]
    }
   ],
   "source": [
    "from enum import Enum\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn import metrics\n",
    "\n",
    "class NodeType(Enum):\n",
    "    USER = 0\n",
    "    MOVIE = 1\n",
    "\n",
    "node_map = []\n",
    "graph = []\n",
    "test_graph = []\n",
    "test_size = 0.1\n",
    "\n",
    "user_map = {}\n",
    "movie_map = {}\n",
    "\n",
    "last_movie_idx = 0\n",
    "with open(\"combined_data_1.txt\") as data_file:\n",
    "    for line in tqdm(data_file):\n",
    "        line = line.strip()\n",
    "        if line.endswith(\":\"):\n",
    "            movie_id = int(line[:-1])\n",
    "                \n",
    "            movie_map[movie_id] = len(node_map)\n",
    "            last_movie_idx = len(node_map)\n",
    "            \n",
    "            for _ in range(5):\n",
    "                node_map.append((NodeType.MOVIE, movie_id))\n",
    "                graph.append([])\n",
    "                test_graph.append([])\n",
    "            \n",
    "        else:\n",
    "            node_info = line.split(\",\")\n",
    "            user_id = int(node_info[0])\n",
    "            rating = int(node_info[1]) - 1\n",
    "            \n",
    "            if user_id < 1200000:\n",
    "                if user_id not in user_map.keys():\n",
    "                    node_map.append((NodeType.USER, user_id))\n",
    "                    graph.append([])\n",
    "                    test_graph.append([])\n",
    "                    \n",
    "                    user_map[user_id] = len(node_map) - 1\n",
    "                    \n",
    "                user_node_idx = user_map[user_id]\n",
    "                \n",
    "                if random.uniform(0, 1) > test_size:\n",
    "                    graph[last_movie_idx + rating].append(user_node_idx)\n",
    "                    graph[user_node_idx].append(last_movie_idx + rating)\n",
    "                else:\n",
    "                    test_graph[last_movie_idx + rating].append(user_node_idx)\n",
    "                    test_graph[user_node_idx].append(last_movie_idx + rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213543"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:30<00:00,  9.07s/it]\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "t = 30\n",
    "w = 5\n",
    "latent_dim = 64\n",
    "\n",
    "corpus = []\n",
    "\n",
    "nodes = list(range(len(node_map)))\n",
    "for _ in tqdm(range(epochs), total = epochs):\n",
    "    random.shuffle(nodes)\n",
    "    for node in nodes:\n",
    "        walk = [node]\n",
    "        for i in range(1, t):\n",
    "            if len(graph[walk[-1]]) == 0:\n",
    "                break\n",
    "            walk.append(random.choice(graph[walk[-1]]))\n",
    "        corpus.append([str(word) for word in walk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(corpus, size = latent_dim, window = w, min_count = 0, sg = 1, hs = 1, workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = []\n",
    "y_real = []\n",
    "N = len(node_map)\n",
    "for user, node in tqdm(enumerate(node_map), total = N):\n",
    "    if node[0] == NodeType.USER:\n",
    "        for movie_rating_node in test_graph[user]:\n",
    "            movie_node = movie_map[node_map[movie_rating_node][1]]\n",
    "            max_score = -1\n",
    "            for rating in range(5):\n",
    "                t_score = model.wv.similarity(str(user), str(movie_node + rating))\n",
    "                if t_score > max_score:\n",
    "                    predicted_rating = rating\n",
    "            predicted_rating += 1\n",
    "            real_rating = movie_rating_node - movie_node + 1\n",
    "            y_predicted.append(predicted_rating)\n",
    "            y_real.append(real_rating)\n",
    "\n",
    "print(metrics.mean_absolute_error(y_real, y_predicted))\n",
    "print(metrics.mean_squared_error(y_real, y_predicted))\n",
    "\n",
    "y_random = [random.randint(1, 5) for i in range(len(y_real))]\n",
    "\n",
    "print(metrics.mean_absolute_error(y_real, y_random))\n",
    "print(metrics.mean_squared_error(y_real, y_random))\n",
    "\n",
    "y_constant = [3 for i in range(len(y_real))]\n",
    "\n",
    "print(metrics.mean_absolute_error(y_real, y_constant))\n",
    "print(metrics.mean_squared_error(y_real, y_constant))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
